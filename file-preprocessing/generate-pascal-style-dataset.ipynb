{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset\n",
    "\n",
    "The purpose of this file is to generate the pascal style dataset that we will use for our ML project. It is mostly automated, apart from having to deal with updates to errors made in the process of annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import zipfile\n",
    "import tqdm\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_repo = '/Users/guillaumekugener/Documents/USC/USC_docs/ml/surgical-training-project/'\n",
    "\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, os.path.join(path_to_repo, 'tools'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drive_dataset import (\n",
    "    SurgicalVideoAnnotation, \n",
    "    extract_and_move_images, \n",
    "    create_retinanet_csv, \n",
    "    fix_S810T1b,\n",
    "    add_missing_muscle,\n",
    "    compile_reannotation_folder,\n",
    "    replace_qc_frames,\n",
    "    get_trial_validation_set, get_trial_test_set\n",
    "    \n",
    ")\n",
    "from utils import plot_frame_with_bb, convert_frame_object_to_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drive directory is the directory of the zip files with all of the annotations. We download this directly from the drive and decompress it. The variable below points to its location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "surgical_git_dir = '/Users/guillaumekugener/Documents/USC/USC_docs/ml/surgical-training-project/'\n",
    "\n",
    "drive_dir = '/Users/guillaumekugener/Downloads/Completed Annotations 1 FPS/'\n",
    "# Move the muscle patch only files (from the drive directory) into the directory below before running this script\n",
    "muscle_patches_dir = '/Users/guillaumekugener/Downloads/muscle-patches/'\n",
    "true_image_dir = '/Users/guillaumekugener/Downloads/1 FPS Reduced/'\n",
    "\n",
    "final_dataset_directory = '/Users/guillaumekugener/Documents/USC/USC_docs/ml/datasets/fps-1-uncropped/'\n",
    "csv_of_total_frames = '/Users/guillaumekugener/Documents/USC/USC_docs/ml/surgical-training-project/data/total_frames_1_fps.csv'\n",
    "\n",
    "frame_rate = 1\n",
    "\n",
    "manually_fixed_cases = os.path.join(surgical_git_dir, 'data/manually_fixed_annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile reannotation data\n",
    "\n",
    "There are a subset of annotations that we want to have reannotated. We want to be able to upload the current annotations in VOTT and edit them, rather than having to start from scratch. This function compiles our folder of interest for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    compile_reannotation_folder(\n",
    "        reannotation_csv = '/Users/guillaumekugener/Downloads/QC Frames Needing Attention - Sheet1.csv',\n",
    "        image_directory = os.path.join(final_dataset_directory, 'JPEGImages'),\n",
    "        complete_annotation_directory = drive_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to download the original frames to put into the dataset. Below, we first unzip all the files to count the total number of frames (in case we need to create empty annotation files for images that do not have annotations (because they have no objects). We copy the images into our dataset at the end of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_zips = [i for i in os.listdir(true_image_dir) if re.search('\\\\.zip$', i)]\n",
    "images_zips.sort()\n",
    "\n",
    "total_frames = {\n",
    "    'trial_id': [],\n",
    "    'frames': []\n",
    "}\n",
    "\n",
    "for z in images_zips:\n",
    "    trial_id = re.search('S[0-9]+T[0-9]+[ab]?', z).group(0)\n",
    "    zf = zipfile.ZipFile(os.path.join(true_image_dir, z), 'r')\n",
    "    total_frames['trial_id'].append(trial_id)\n",
    "    total_frames['frames'].append(len([i for i in zf.namelist() if re.search('\\\\.jpeg$', i)]))\n",
    "    zf.close()\n",
    "\n",
    "pd.DataFrame(total_frames).to_csv(csv_of_total_frames, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames = pd.read_csv(csv_of_total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zips = [i for i in os.listdir(drive_dir) if re.search('annotations\\\\.zip$', i)]\n",
    "all_zips.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to run detection with yolo\n",
    "if False:\n",
    "    for i in all_zips:\n",
    "        tid = re.sub('\\\\-.*', '', i)\n",
    "        ds_name = 'fps-1-uncropped-20200914'\n",
    "#         print(f\"ffmpeg -framerate 1 -i /home/ec2-user/datasets/{ds_name}/JPEGImages/{tid}_frame_%08d.jpeg ./Videos/{tid}.mp4\")\n",
    "        print(f\"python detect_video.py --classes /home/ec2-user/datasets/{ds_name}/classes.name --num_classes 8 --weights ./checkpoints/yolov3_train_11.tf --video /home/ec2-user/datasets/{ds_name}/Videos/{tid}.mp4 --output_stats /home/ec2-user/datasets/{ds_name}/yolo/{tid}_stats.pkl --yolo_score_threshold 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_fix = []\n",
    "all_dataset_objects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all the trials and parse all the annotations we have so far\n",
    "# all_zips = ['S314T1-annotations.zip']\n",
    "redos = []\n",
    "for z in tqdm.tqdm(all_zips):\n",
    "    trial_id = re.search('S[0-9]+T[0-9]+[ab]?', z).group(0)\n",
    "    frames_total = total_frames[total_frames['trial_id']==trial_id]['frames'].values[0]\n",
    "    \n",
    "    try:\n",
    "        ex = SurgicalVideoAnnotation(\n",
    "            trial_id=trial_id,\n",
    "            total_frames=frames_total,\n",
    "            file_path=os.path.join(drive_dir, z),\n",
    "            output_directory=final_dataset_directory,\n",
    "            delete_at_end=True,\n",
    "            annotations_only=True,\n",
    "            manually_fixed_cases=manually_fixed_cases\n",
    "        )\n",
    "    except:\n",
    "        print('This trial failed' + z)\n",
    "        redos.append(z)\n",
    "        continue\n",
    "    \n",
    "    frames_to_fix = frames_to_fix + ex.too_many_tags_frames\n",
    "    all_dataset_objects = all_dataset_objects + ex.frame_objects\n",
    "    \n",
    "#     time.sleep(0.5) # See if this fixes our bug..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if frame_rate == 10:\n",
    "    all_dataset_objects.append({\n",
    "        'name': 'S306T1_frame_00002212.jpeg',\n",
    "        'x1': int((492+574)/2),\n",
    "        'y1': int((260+370)/2),\n",
    "        'x2': int((670+641)/2),\n",
    "        'y2': 720,\n",
    "        'class': 'suction'\n",
    "    })\n",
    "    print([i for i in all_dataset_objects if i['name'] in ['S306T1_frame_00002212.jpeg', 'S306T1_frame_00002213.jpeg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to add the frames from the csvs\n",
    "all_csv_annotations = [i for i in os.listdir(drive_dir) if re.search('\\\\.csv$', i)]\n",
    "all_csv_annotations.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the images into our dataset. We should only move the trial for which we have annotations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_and_move_images(\n",
    "    dir_with_image_zips=true_image_dir,\n",
    "    output_directory=final_dataset_directory,\n",
    "    trials_to_process=[re.sub('(\\\\.csv$)|(\\\\-.*)|(\\\\.zip$)', '', i) for i in all_zips + all_csv_annotations]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file with image sizes for all of the trials\n",
    "image_sizes_all = {'trial_id': [], 'w': [], 'h': []}\n",
    "for tid in [re.sub('(\\\\.csv$)|(\\\\-.*)|(\\\\.zip$)', '', i) for i in all_zips + all_csv_annotations]:\n",
    "    img_size = cv2.imread(os.path.join(final_dataset_directory, 'JPEGImages', f\"{tid}_frame_00000001.jpeg\")).shape\n",
    "    image_sizes_all['trial_id'].append(re.sub('[a-z]$', '', tid))\n",
    "    image_sizes_all['w'].append(img_size[1])\n",
    "    image_sizes_all['h'].append(img_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_frame_sizes = pd.DataFrame(image_sizes_all).drop_duplicates().reset_index(drop=True)\n",
    "trial_frame_sizes.to_csv(f\"{final_dataset_directory}/image_sizes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through and make the new data\n",
    "dataset_formatted = []\n",
    "for cti in tqdm.tqdm(range(len(all_csv_annotations))):\n",
    "    # Need to get the image size for this trial\n",
    "    current_trial_id = re.sub('\\\\-.*', '', all_csv_annotations[cti])\n",
    "    example_export = pd.read_csv(os.path.join(drive_dir, all_csv_annotations[cti]))\n",
    "\n",
    "    # Some meta data we need\n",
    "    n_frames = total_frames.loc[total_frames['trial_id'].str.contains(current_trial_id),'frames'].iloc[0]\n",
    "    all_frames = [current_trial_id + '_frame_' + str(i).zfill(8) + '.jpeg' for i in range(1, 1+n_frames)]\n",
    "    img_size = cv2.imread(os.path.join(final_dataset_directory, 'JPEGImages', example_export.at[0, 'image'])).shape\n",
    "\n",
    "    frame_objects= []\n",
    "    frames = {}\n",
    "    for i in range(example_export.shape[0]):\n",
    "        # Need the width and height\n",
    "        # Need tools\n",
    "        image = example_export.at[i,'image']\n",
    "        xmin = floor(example_export.at[i,'xmin'])\n",
    "        ymin = floor(example_export.at[i,'ymin'])\n",
    "        xmax = min(img_size[1], ceil(example_export.at[i,'xmax']))\n",
    "        ymax = min(img_size[0], ceil(example_export.at[i,'ymax']))\n",
    "        label = example_export.at[i,'label']\n",
    "    \n",
    "    \n",
    "        # Run some checks\n",
    "        if label == 'undefined':\n",
    "            print('Undefined label: ' + image)\n",
    "            \n",
    "        if len(label.split(',')) > 1:\n",
    "            print('Multi-label: ' + image)\n",
    "        \n",
    "        \n",
    "        if image not in frames:\n",
    "            frames[image] = { 'name': image, 'height': img_size[0], 'width': img_size[1], 'tools': [] }\n",
    "\n",
    "        frames[image]['tools'].append({'coordinates': [(xmin, ymin), (xmax, ymax)], 'type': label})\n",
    "        \n",
    "        dataset_formatted.append({\n",
    "            'name': image, \n",
    "            'x1': xmin, \n",
    "            'y1': ymin, \n",
    "            'x2': xmax, \n",
    "            'y2': ymax, \n",
    "            'class': label\n",
    "        })\n",
    "        \n",
    "    # Have to fill in blank\n",
    "    missing_frames = [f for f in all_frames if f not in frames.keys()]\n",
    "    for f in missing_frames:\n",
    "        frames[f] = { 'name': f, 'height': img_size[0], 'width': img_size[1], 'tools': [] }\n",
    "        dataset_formatted.append({'name': f, 'x1': '', 'y1': '', 'x2': '', 'y2': '', 'class': ''})\n",
    "\n",
    "    # Now make the frame objects\n",
    "    frame_objects = [frames[f] for f in frames]\n",
    "        \n",
    "    # And make their xmls\n",
    "    for fo in frame_objects:\n",
    "        convert_frame_object_to_xml(\n",
    "            frame_obj=fo, \n",
    "            destination=os.path.join(final_dataset_directory, 'Annotations')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects_ds_df = pd.DataFrame(all_dataset_objects + dataset_formatted)\n",
    "all_objects_ds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects_ds_df[all_objects_ds_df['name'].str.contains('S810T1b')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the class map for the dataset below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = pd.DataFrame({'class': all_objects_ds_df['class'].unique()})\n",
    "class_map = class_map[class_map['class'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map.to_csv(os.path.join(final_dataset_directory, 'classes.name'), sep='\\t', header=False, index=False)\n",
    "class_map_retina = class_map.copy()\n",
    "class_map_retina['index'] = [i for i in range(class_map_retina.shape[0])]\n",
    "class_map_retina.to_csv(\n",
    "    os.path.join(\n",
    "        final_dataset_directory, \n",
    "        'retina_classes.csv'\n",
    "    ), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look for undefined objects. We then manually inspect and fix these and save the results to a csv. The csv is then used in the future to fix the labels so we do not have to deal with this manual process again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_objects_ds_df[all_objects_ds_df['class']=='undefined'].shape[0] > 0:\n",
    "    print(f\"There are {all_objects_ds_df[all_objects_ds_df['class']=='undefined'].shape[0]} undefined objects\")\n",
    "    all_objects_ds_df[all_objects_ds_df['class']=='undefined'].to_csv(os.path.join(surgical_git_dir, 'data', todays_date + '_fixed_annotations.csv'), index=False) # These are the ones we have to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_objects_ds_df[all_objects_ds_df['name']=='S109T1_frame_00000087.jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix my naming mistakes\n",
    "all_objects_ds_df = fix_S810T1b(\n",
    "    image_dir = os.path.join(final_dataset_directory, 'JPEGImages'),\n",
    "    annotations_dir = os.path.join(final_dataset_directory, 'Annotations'),\n",
    "    complete_set_df = all_objects_ds_df.copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects_ds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muscle patch for a whole set of images were missing so adding them here\n",
    "all_objects_ds_df = add_missing_muscle(\n",
    "    muscle_annotations_path=muscle_patches_dir,\n",
    "    image_dir = os.path.join(final_dataset_directory, 'JPEGImages'),\n",
    "    annotations_dir= os.path.join(final_dataset_directory, 'Annotations'),\n",
    "    complete_set_df = all_objects_ds_df.copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects_ds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the poorly annotated frames with the QC ones\n",
    "all_objects_ds_df = replace_qc_frames(\n",
    "    reannotation_csv = '/Users/guillaumekugener/Downloads/QC Frames Needing Attention - Sheet1.csv',\n",
    "    qc_directory='/Users/guillaumekugener/Downloads/QC Annotations/QC-PascalVOC-export/Annotations',\n",
    "    final_dataset_directory=final_dataset_directory,\n",
    "    complete_set_df = all_objects_ds_df.copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects_ds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects_ds_df = all_objects_ds_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure how these get added...\n",
    "all_objects_ds_df = all_objects_ds_df[~all_objects_ds_df['name'].isin(['._S310T1_frame_00000003.jpeg', '._S310T1_frame_00000004.jpeg'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects_ds_df = all_objects_ds_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objects_ds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have all of the frames and annotations in the dataset (we should not be missing anything)\n",
    "for ti, tid in enumerate(total_frames['trial_id']):\n",
    "    total_expected = total_frames.loc[ti, 'frames']\n",
    "    total_actual = all_objects_ds_df[all_objects_ds_df['name'].str.contains(tid)]['name'].unique()\n",
    "    \n",
    "    if len(total_actual) != total_expected:\n",
    "        print(f\"{tid}. Expected: {total_expected}, actual: {len(total_actual)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can catch errors in the annotations below. We need to manually fix these\n",
    "for i in range(len(frames_to_fix)):\n",
    "    print(frames_to_fix[i]['name'])\n",
    "    plot_frame_with_bb(\n",
    "        image_path=os.path.join(final_dataset_directory, 'JPEGImages', frames_to_fix[i]['name']),\n",
    "        annotation_path=os.path.join(final_dataset_directory, 'Annotations', re.sub('\\\\.jpeg$', '.xml', frames_to_fix[i]['name'])),\n",
    "        only_undefined=False        \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_in_current_ds = sum(total_frames[total_frames['trial_id'].isin([re.sub('(\\\\-.*)|(\\\\.zip$)', '', i) for i in all_zips + all_csv_annotations])]['frames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total frames in current version of ds: {frames_in_current_ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames_dataset = all_objects_ds_df['name'].unique()\n",
    "all_frames_dataset.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC Annotations\n",
    "\n",
    "Below, we save all of the frames with the annotations include so that we can visually inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to QC are data (which we will want to do later, per recommendations made about clean data)\n",
    "if False:\n",
    "    for i, f in progressbar.progressbar(enumerate(all_frames_dataset)):\n",
    "        # In case this has to stop for some reason\n",
    "        if os.path.isfile(os.path.join(final_dataset_directory, 'AnnotationValidation', re.sub('_.*', '', f), f)):\n",
    "            continue\n",
    "    #     print(f)\n",
    "        try:\n",
    "            os.mkdir(os.path.join(final_dataset_directory, 'AnnotationValidation', re.sub('_.*', '', f)))\n",
    "        except:\n",
    "            pass\n",
    "        plot_frame_with_bb(\n",
    "            image_path=os.path.join(final_dataset_directory, 'JPEGImages', f),\n",
    "            annotation_path=os.path.join(final_dataset_directory, 'Annotations', re.sub('\\\\.jpeg$', '.xml', f)),\n",
    "            only_undefined=False,\n",
    "            save_path=os.path.join(final_dataset_directory, 'AnnotationValidation', re.sub('_.*', '', f), f)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training, validation, test sets\n",
    "\n",
    "Below, we create the training and validation csvs. For testing, we will use additional videos not in our original 46 (as this will have the least bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These were randomly selected\n",
    "test_trials = get_trial_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These were randomly selected\n",
    "validation_trials = get_trial_validation_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_relevant_o = {\n",
    "    'train': [re.sub('\\\\.jpeg$', '', i) for i in all_frames_dataset if (re.sub('_.*', '', i) not in validation_trials) and (re.sub('_.*', '', i) not in test_trials)],\n",
    "    'val': [re.sub('\\\\.jpeg$', '', i) for i in all_frames_dataset if re.sub('_.*', '', i) in validation_trials],\n",
    "    'test': [re.sub('\\\\.jpeg$', '', i) for i in all_frames_dataset if re.sub('_.*', '', i) in test_trials]\n",
    "}\n",
    "\n",
    "trials_relevant = {}\n",
    "for k in frames_relevant_o:\n",
    "    trials_relevant[k] = [i for i in set([re.sub('_frame.*', '', j) for j in frames_relevant_o[k]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in ['train', 'val', 'test']:\n",
    "    pascal_training_csv = pd.DataFrame({ 'name': frames_relevant_o[g], 'inc': 1})\n",
    "    print(f\"Dataset {g} size: {pascal_training_csv.shape[0]} frames\")\n",
    "    pascal_training_csv.to_csv(\n",
    "        os.path.join(final_dataset_directory, 'ImageSets/Main', 'surgical_1fps_' + g + '.txt'),\n",
    "        sep = '\\t', header=False, index=False\n",
    "    )\n",
    "    \n",
    "#     pascal_training_csv.head(100).to_csv(\n",
    "#         os.path.join(final_dataset_directory, 'ImageSets/Main', 'small_surgical_1fps_' + g + '.txt'),\n",
    "#         sep = '\\t', header=False, index=False\n",
    "#     )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to convert the class label to an index first. \n",
    "# Read in the class.name file and use that order\n",
    "class_map = pd.read_csv(os.path.join(final_dataset_directory, 'classes.name'), header=None)\n",
    "class_dict_mapping = {}\n",
    "for ki, k in enumerate(class_map[0]):\n",
    "    class_dict_mapping[k] = ki\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is for the retinanet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_dir_prefix = '/home/ec2-user/datasets/fps-1-uncropped-20210205/JPEGImages/'\n",
    "local_dir_predix = '/Users/guillaumekugener/Documents/USC/USC_docs/ml/datasets/fps-1-uncropped/JPEGImages/'\n",
    "\n",
    "# For AWS files\n",
    "create_retinanet_csv(\n",
    "    all_objects_ds_df=all_objects_ds_df,\n",
    "    dir_prefix=aws_dir_prefix,\n",
    "    final_dataset_directory=final_dataset_directory,\n",
    "    csv_name='retinanet_surgical_1fps',\n",
    "    grouping=trials_relevant\n",
    ")\n",
    "\n",
    "# For local files\n",
    "create_retinanet_csv(\n",
    "    all_objects_ds_df=all_objects_ds_df,\n",
    "    dir_prefix=local_dir_predix,\n",
    "    final_dataset_directory=final_dataset_directory,\n",
    "    csv_name='local_retinanet_surgical_1fps',\n",
    "    grouping=trials_relevant\n",
    ")\n",
    "\n",
    "# validation_indices = all_objects_ds_df['name'].str.contains('|'.join(validation_trials))\n",
    "# retinanet_training_csv = all_objects_ds_df[~validation_indices].copy()\n",
    "# retinanet_validation_csv = all_objects_ds_df[validation_indices].copy()\n",
    "\n",
    "# retinanet_training_csv['name'] = dir_prefix + retinanet_training_csv['name']\n",
    "# retinanet_validation_csv['name'] = dir_prefix + retinanet_validation_csv['name']\n",
    "\n",
    "# # We need to set the full path    \n",
    "# retinanet_training_csv.to_csv(\n",
    "#     os.path.join(final_dataset_directory, 'ImageSets/Main', 'retinanet_surgical_1fps_train.csv'),\n",
    "#     sep=',', header=False, index=False\n",
    "# )\n",
    "# retinanet_validation_csv.to_csv(\n",
    "#     os.path.join(final_dataset_directory, 'ImageSets/Main', 'retinanet_surgical_1fps_validation.csv'),\n",
    "#     sep=',', header=False, index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats\n",
    "\n",
    "Gives an overview of the dataset (number of frames in training, validation, and number of tools, number of trials, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_on_ds = {\n",
    "    'Training': pd.read_csv(\n",
    "        os.path.join(\n",
    "            final_dataset_directory, \n",
    "            'ImageSets/Main', \n",
    "            'retinanet_surgical_1fps_train.csv'\n",
    "        ), names=['file', 'x1', 'y1', 'x2', 'y2', 'class']),\n",
    "    'Validation': pd.read_csv(\n",
    "        os.path.join(\n",
    "            final_dataset_directory, \n",
    "            'ImageSets/Main', \n",
    "            'retinanet_surgical_1fps_val.csv'\n",
    "        ), names=['file', 'x1', 'y1', 'x2', 'y2', 'class']),\n",
    "    'Testing': pd.read_csv(\n",
    "        os.path.join(\n",
    "            final_dataset_directory, \n",
    "            'ImageSets/Main', \n",
    "            'retinanet_surgical_1fps_test.csv'\n",
    "        ), names=['file', 'x1', 'y1', 'x2', 'y2', 'class']),\n",
    "}\n",
    "output_string = \"\"\n",
    "for g in data_on_ds:\n",
    "    stat_df = data_on_ds[g][['x1','class']].groupby('class').agg(['count'])\n",
    "    output_string += f\"--- {g} info ---\\n\\n\"\n",
    "    for i in range(len(stat_df.values)):\n",
    "        tool = stat_df.index.values[i]\n",
    "        total = stat_df.values[i][0]\n",
    "        if tool == '':\n",
    "            tool = 'None'\n",
    "        output_string += f\"\\t{tool}: {total} ({round(total/data_on_ds[g].shape[0]*100, 1)}%)\\n\"\n",
    "    output_string += f\"\\nTotal frames: {len(set(data_on_ds[g]['file']))}\\n\\n\"\n",
    "\n",
    "    \n",
    "text_file = open(os.path.join(final_dataset_directory, 'ImageSets/Main', 'stats_' + todays_date + '.txt'), \"w\")\n",
    "text_file.write(output_string)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retinanet-dev",
   "language": "python",
   "name": "retinanet-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
